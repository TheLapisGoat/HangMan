{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1690274151728
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "import random\n",
        "random.seed(218)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1690274152007
        },
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "alphabet = set(['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z'])\n",
        "\n",
        "def generate_combinations(word):\n",
        "    # num_combinations_per_word = num_combinations(len(word)) + 1\n",
        "    word = word.strip()\n",
        "    num_combinations = 7\n",
        "\n",
        "    combinations = set()\n",
        "\n",
        "    characters = set()\n",
        "    for c in word:\n",
        "        characters.add(c)\n",
        "\n",
        "    # while len(combinations) < num_combinations_per_word:\n",
        "    #     indexes = random.sample(range(len(word)), random.randint(1, max_blanks))\n",
        "    #     new_word = list(word)\n",
        "\n",
        "    #     for idx in indexes:\n",
        "    #         new_word[idx] = '_'\n",
        "    #     combinations.add(''.join(new_word))\n",
        "\n",
        "    for i in range(1, len(characters) + 1):\n",
        "        for j in range(num_combinations):\n",
        "\n",
        "            removal_characters = random.sample(list(characters), k = i)\n",
        "            new_word = word\n",
        "\n",
        "            for c in removal_characters:\n",
        "                new_word = new_word.replace(c, '_')\n",
        "            combinations.add(new_word)\n",
        "\n",
        "    return list(combinations)\n",
        "\n",
        "def create_hangman_data(data_file_path, input_file_path, target_file_path, wrong_guesses_file_path):\n",
        "    with open(data_file_path, 'r') as f:\n",
        "        words = f.read().splitlines()\n",
        "\n",
        "    input_data = []\n",
        "    target_data = []\n",
        "    wrong_guesses = []\n",
        "    maxlen = 0\n",
        "\n",
        "    for word in words:\n",
        "        combinations = generate_combinations(word)\n",
        "\n",
        "        total_characters = set(list(word.strip()))\n",
        "        total_wrong_guesses = alphabet.difference(total_characters)\n",
        "\n",
        "        for combination in combinations:\n",
        "            for i in range(0, 12):\n",
        "                cur_wrong_guesses = random.sample(list(total_wrong_guesses), k = min(i, 26 - len(set(list(word.strip())))))\n",
        "                cur_wrong_guesses = ''.join(cur_wrong_guesses)\n",
        "                input_data.append(combination)\n",
        "                target_data.append(word)\n",
        "                wrong_guesses.append(cur_wrong_guesses)\n",
        "        \n",
        "        maxlen = max(maxlen, len(word))\n",
        "    \n",
        "    shuffled_idx = random.sample(range(len(input_data)), k = len(input_data))\n",
        "    input_data = [input_data[i] for i in shuffled_idx]\n",
        "    target_data = [target_data[i] for i in shuffled_idx]\n",
        "    wrong_guesses = [wrong_guesses[i] for i in shuffled_idx]\n",
        "\n",
        "    with open(input_file_path, 'w') as f:\n",
        "        f.write('\\n'.join(input_data))\n",
        "\n",
        "    with open(target_file_path, 'w') as f:\n",
        "        f.write('\\n'.join(target_data))\n",
        "    \n",
        "    with open(wrong_guesses_file_path, 'w') as f:\n",
        "        f.write('\\n'.join(wrong_guesses))\n",
        "\n",
        "    return len(input_data), maxlen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1690274153211
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "data_file_path = \"words_250000_train.txt\"\n",
        "input_file_path = \"input_train.txt\"\n",
        "target_file_path = \"target_train.txt\" \n",
        "wrong_guesses_file_path = \"wrong_guesses.txt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "gather": {
          "logged": 1690134992737
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "data_size, MAX_SEQ_LEN = create_hangman_data(data_file_path=data_file_path, input_file_path=input_file_path, target_file_path=target_file_path, wrong_guesses_file_path=wrong_guesses_file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1690274155393
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "print(\"Size of input training data is %d\" % data_size)\n",
        "print(\"Max length of a word is %d\" % MAX_SEQ_LEN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "gather": {
          "logged": 1690275032351
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "char2idx = {'<PAD>' : 0}\n",
        "idx2char = ['<PAD>']\n",
        "\n",
        "for i in range(26):\n",
        "    char2idx[chr(i + ord('a'))] = i + 1\n",
        "    idx2char.append(chr(ord('a') + i))\n",
        "\n",
        "char2idx['_'] = 27\n",
        "idx2char.append('_')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "gather": {
          "logged": 1690275033739
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "def get_coded_sequence(word):\n",
        "    word = word.strip()\n",
        "    seq = list(word)\n",
        "    seq = seq + ['<PAD>'] * (MAX_SEQ_LEN - len(seq))\n",
        "    for idx, c in enumerate(seq):\n",
        "        seq[idx] = char2idx[c]\n",
        "    \n",
        "    return seq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "gather": {
          "logged": 1690276070732
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "alphabets = set(['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z'])\n",
        "def data_generator(input_file, target_file, wrong_guesses_file):\n",
        "    with open(input_file) as f_input, open(target_file) as f_target, open(wrong_guesses_file) as f_wguess:\n",
        "        for input_word, target_word, wrong_guess in zip(f_input, f_target, f_wguess):\n",
        "            input_tokens = get_coded_sequence(input_word)\n",
        "            target_tokens = np.zeros(26)\n",
        "            incorrect_tokens = np.zeros(26)\n",
        "            correct_tokens = np.zeros(26)\n",
        "\n",
        "            present_chars = set(list(input_word.strip()))\n",
        "            missing_chars = set(list(target_word.strip()))\n",
        "            missing_chars = missing_chars.difference(present_chars)\n",
        "            for c in missing_chars:\n",
        "                target_tokens[ord(c) - ord('a')] = 1\n",
        "            \n",
        "            for c in present_chars:\n",
        "                if c == '_':\n",
        "                    continue\n",
        "                correct_tokens[ord(c) - ord('a')] = 1\n",
        "\n",
        "            for c in list(wrong_guess.strip()):\n",
        "                incorrect_tokens[ord(c) - ord('a')] = 1\n",
        "\n",
        "            yield (input_tokens, correct_tokens, incorrect_tokens), target_tokens\n",
        "            \n",
        "\n",
        "            "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "gather": {
          "logged": 1690276071864
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "physical_devices = tf.config.list_physical_devices('GPU')\n",
        "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
        "tf.keras.backend.clear_session()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "gather": {
          "logged": 1690276081347
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 2048\n",
        "MAX_SEQ_LEN = 29"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "gather": {
          "logged": 1690276084538
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "train_dataset = tf.data.Dataset.from_generator(\n",
        "    lambda: data_generator(input_file_path, target_file_path, wrong_guesses_file_path),\n",
        "    output_signature = (\n",
        "        (tf.TensorSpec(shape = (MAX_SEQ_LEN,), dtype = tf.int32), tf.TensorSpec(shape = (26,), dtype = tf.int32), tf.TensorSpec(shape = (26,), dtype = tf.int32)),\n",
        "        tf.TensorSpec(shape = (26,), dtype = tf.int32)\n",
        "    )\n",
        ")\n",
        "train_dataset = train_dataset.batch(BATCH_SIZE, drop_remainder = False, num_parallel_calls = tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "gather": {
          "logged": 1690274159297
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from keras import Input, Model\n",
        "from keras.layers import LSTM, Bidirectional, Embedding, Dense, TimeDistributed, Attention, Concatenate, Masking, GlobalMaxPooling1D, Dropout, GlobalAveragePooling1D\n",
        "from keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "gather": {
          "logged": 1690274159478
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "adam_opt = Adam(learning_rate = 0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "gather": {
          "logged": 1690274247791
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "LATENT_DIM = 256\n",
        "\n",
        "input1 = Input(shape=(MAX_SEQ_LEN,), name = \"Input_Word\")\n",
        "\n",
        "embedding_layer = Embedding(input_dim = 28, output_dim = 40, mask_zero = True, name = \"Embedding_Layer\")\n",
        "emb_input = embedding_layer(input1)\n",
        "\n",
        "bilstm_layer = Bidirectional(LSTM(LATENT_DIM, return_sequences = True, name = \"Bidirection_LSTM_Layer\", dropout = 0.1))\n",
        "lstm_output = bilstm_layer(emb_input)\n",
        "\n",
        "pool_layer = GlobalMaxPooling1D(name = \"MaxPooling_Layer\")\n",
        "lstm_output = pool_layer(lstm_output)\n",
        "\n",
        "input2 = Input(shape = (26,), name = \"Correct_Guesses\")\n",
        "input3 = Input(shape = (26,), name = \"Incorrect_Guesses\")\n",
        "\n",
        "\n",
        "dense_layer = Dense(128, activation = 'relu', name = \"Dense_Layer\")\n",
        "dense_layer1 = Dense(128, activation = 'relu', name = \"Dense_Layer1\")\n",
        "correct_guess_output = dense_layer(input2)\n",
        "correct_guess_output = Dropout(0.1, seed = 218)(correct_guess_output)\n",
        "incorrect_guess_output = dense_layer1(input3)\n",
        "incorrect_guess_output = Dropout(0.1, seed = 218)(incorrect_guess_output)\n",
        "\n",
        "\n",
        "concat_layer = Concatenate(name = \"Concatenate_Layer\")\n",
        "guess_output = concat_layer([correct_guess_output, incorrect_guess_output])\n",
        "\n",
        "dense_layer2 = Dense(256, activation = 'relu', name = \"Dense_Layer2\")\n",
        "guess_output = dense_layer2(guess_output)\n",
        "guess_output = Dropout(0.2, seed = 218)(guess_output)\n",
        "\n",
        "\n",
        "concat_output = concat_layer([lstm_output, guess_output])\n",
        "\n",
        "dense_layera = Dense(512, activation='relu', name = \"Dense_LayerA\")\n",
        "dense_layerb = Dense(256, activation='relu', name = \"Dense_LayerB\")\n",
        "dense_layerc = Dense(26, activation='sigmoid', name = \"Dense_LayerC\")\n",
        "output = dense_layera(concat_output)\n",
        "output = Dropout(0.3, seed = 218)(output)\n",
        "output = dense_layerb(output)\n",
        "output = Dropout(0.2, seed = 218)(output)\n",
        "output = dense_layerc(output)\n",
        "\n",
        "model = Model([input1, input2, input3], output)\n",
        "\n",
        "model.compile(optimizer = adam_opt, loss='binary_focal_crossentropy', metrics=['acc'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "gather": {
          "logged": 1690274249680
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " Correct_Guesses (InputLayer)   [(None, 26)]         0           []                               \n",
            "                                                                                                  \n",
            " Incorrect_Guesses (InputLayer)  [(None, 26)]        0           []                               \n",
            "                                                                                                  \n",
            " Dense_Layer (Dense)            (None, 128)          3456        ['Correct_Guesses[0][0]']        \n",
            "                                                                                                  \n",
            " Dense_Layer1 (Dense)           (None, 128)          3456        ['Incorrect_Guesses[0][0]']      \n",
            "                                                                                                  \n",
            " Input_Word (InputLayer)        [(None, 29)]         0           []                               \n",
            "                                                                                                  \n",
            " dropout_5 (Dropout)            (None, 128)          0           ['Dense_Layer[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_6 (Dropout)            (None, 128)          0           ['Dense_Layer1[0][0]']           \n",
            "                                                                                                  \n",
            " Embedding_Layer (Embedding)    (None, 29, 40)       1120        ['Input_Word[0][0]']             \n",
            "                                                                                                  \n",
            " Concatenate_Layer1 (Concatenat  (None, 256)         0           ['dropout_5[0][0]',              \n",
            " e)                                                               'dropout_6[0][0]']              \n",
            "                                                                                                  \n",
            " bidirectional_1 (Bidirectional  (None, 29, 512)     608256      ['Embedding_Layer[0][0]']        \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " Dense_Layer2 (Dense)           (None, 256)          65792       ['Concatenate_Layer1[0][0]']     \n",
            "                                                                                                  \n",
            " MaxPooling_Layer (GlobalMaxPoo  (None, 512)         0           ['bidirectional_1[0][0]']        \n",
            " ling1D)                                                                                          \n",
            "                                                                                                  \n",
            " dropout_7 (Dropout)            (None, 256)          0           ['Dense_Layer2[0][0]']           \n",
            "                                                                                                  \n",
            " Concatenate_Layer2 (Concatenat  (None, 768)         0           ['MaxPooling_Layer[0][0]',       \n",
            " e)                                                               'dropout_7[0][0]']              \n",
            "                                                                                                  \n",
            " Dense_LayerA (Dense)           (None, 512)          393728      ['Concatenate_Layer2[0][0]']     \n",
            "                                                                                                  \n",
            " dropout_8 (Dropout)            (None, 512)          0           ['Dense_LayerA[0][0]']           \n",
            "                                                                                                  \n",
            " Dense_LayerB (Dense)           (None, 256)          131328      ['dropout_8[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_9 (Dropout)            (None, 256)          0           ['Dense_LayerB[0][0]']           \n",
            "                                                                                                  \n",
            " Dense_LayerC (Dense)           (None, 26)           6682        ['dropout_9[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,213,818\n",
            "Trainable params: 1,213,818\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "gather": {
          "logged": 1690136864081
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "model_checkpoint = ModelCheckpoint(\"checkpoints/weights.{epoch:02d}-{acc:.4f}.hdf5\", monitor = \"acc\")\n",
        "early_stopping = EarlyStopping(monitor='acc', patience=2, restore_best_weights = True)\n",
        "callbacks_list = [model_checkpoint, early_stopping]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1690135209981
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "model.fit(train_dataset, epochs = 5, callbacks = callbacks_list, verbose = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1690072001213
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "model.save('model_weights.h5')"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "tfgpu"
    },
    "kernelspec": {
      "display_name": "Python (tf-cudnn8.6)",
      "language": "python",
      "name": "tfgpu"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
